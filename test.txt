"""        def __init__(self, 768, Entity_num=10000, Relation_num=50):        '''        initialize self according to dataset, you may use custom entities and relations during the training process        '''        self.model=torch.nn.Embedding(Entity_num,768)        self.model2=torch.nn.Embedding(Entity_num,768)        self.model3=torch.nn.Parameter(torch.randn((50,768)))         self.model3=torch.nn.Parameter(torch.randn((50,768)),requires_grad=True)         self.loss_fun=torch.nn.MarginRankingLoss(margin=1.0)        self.relation=torch.nn.Parameter(torch.rand(Entity_num,50),requires_grad=True)         self.s_loss_fun=torch.nn.MSELoss()        self.optimizer = torch.optim.Adam(params=[self.model.weight,self.model2.weight,self.model3,self.relation], lr=3e-3)    def forward(self):        '''        builds the computational graph, which accepts inputs as entities and relations of triplets        outputs the head and tail entities of theprojected triples        '''        x=self.model3-self.model        x1=self.model3-self.model2        x2=F.cosine_similarity(x,x1.view(50,-1),dim=1)         s=x2.sum()        sloss=self.s_loss_fun(s,torch.tensor([0.]))        total_loss=sloss        return x2,total_loss    def train_(self,triplets,t_triplets):         '''        function that accepts a data batch, if training is set to true,        applying the fixed_point loss will be the task to perform,         else predicting the role of entities in a given relationship is to be done          '''        head=triplets[:,0]        middle=triplets[:,1]        tail=triplets[:,2]        h_vector=self.model(head)        m_vector=self.model2(middle)        t_vector=self.model2(tail)        score1=F.cosine_similarity(h_vector,m_vector,dim=1)        score2=F.cosine_similarity(m_vector,t_vector,dim=1)        total_loss=F.relu(1.+score1-score2)        #print(self.relationship(head).size(),(self.relationship(head)*self.model3).size())        #re_loss=F.relu(self.relationship(middle)-F.cosine_similarity((self.relationship(head)*self.model3).view(1,-1),(self.relationship(tail)*self.model3).view(1,-1)),dim=1))        total_loss=total_loss.mean()        h_t=t_triplets[:,0]        m_t=t_triplets[:,1]        t_t=t_triplets[:,2]        h_vector_t=self.model(h_t)        m_vector_t=self.model2(m_t)        t_vector_t=self.model2(t_t)        score1_t=F.cosine_similarity(h_vector_t,m_vector_t,dim=1)        score2_t=F.cosine_similarity(m_vector_t,t_vector_t,dim=1)        total_loss_t=F.relu(1.+score1_t-score2_t)        total_loss_t=total_loss_t.mean()        #re_loss=F.relu(self.relationship(middle)-F.cosine_similarity((self.relationship(head)*self.model3).view(1,-1),(self.relationship(tail)*self.model3
